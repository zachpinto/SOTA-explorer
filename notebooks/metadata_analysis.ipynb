{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-13T20:28:31.753163Z",
     "start_time": "2024-06-13T20:28:31.747923Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:28:32.107158Z",
     "start_time": "2024-06-13T20:28:32.084134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# count total number of JSON files\n",
    "DATA_DIR = \"../data/raw\"\n",
    "\n",
    "json_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.json')]\n",
    "total_files = len(json_files)\n",
    "\n",
    "print(f\"Total number of JSON files: {total_files}\")"
   ],
   "id": "c257653cf661d7b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of JSON files: 23045\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:28:33.388734Z",
     "start_time": "2024-06-13T20:28:33.363635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Categorize and count by type\n",
    "file_types = {\n",
    "    'areas': 0,\n",
    "    'tasks': 0,\n",
    "    'task': 0,\n",
    "    'evaluations': 0,\n",
    "    'evaluation_results': 0,\n",
    "    'parents': 0,\n",
    "    'children': 0,\n",
    "}\n",
    "\n",
    "for file in json_files:\n",
    "    if file.startswith(\"areas\"):\n",
    "        file_types['areas'] += 1\n",
    "    elif file.startswith(\"tasks_\"):\n",
    "        file_types['tasks'] += 1\n",
    "    elif file.startswith(\"task_\") and not file.endswith(\"_parents.json\") and not file.endswith(\"_children.json\") and not file.endswith(\"_evaluations.json\"):\n",
    "        file_types['task'] += 1\n",
    "    elif file.startswith(\"task_\") and file.endswith(\"_parents.json\"):\n",
    "        file_types['parents'] += 1\n",
    "    elif file.startswith(\"task_\") and file.endswith(\"_children.json\"):\n",
    "        file_types['children'] += 1\n",
    "    elif file.startswith(\"task_\") and file.endswith(\"_evaluations.json\"):\n",
    "        file_types['evaluations'] += 1\n",
    "    elif file.startswith(\"evaluation_\") and file.endswith(\"_results.json\"):\n",
    "        file_types['evaluation_results'] += 1\n",
    "        \n",
    "print(\"File counts by type: \")\n",
    "for file_type, count in file_types.items():\n",
    "    print(f\"{file_type}: {count}\")\n"
   ],
   "id": "a3f2d55a02d232d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File counts by type: \n",
      "areas: 1\n",
      "tasks: 16\n",
      "task: 3371\n",
      "evaluations: 3371\n",
      "evaluation_results: 9544\n",
      "parents: 3371\n",
      "children: 3371\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T20:35:08.582652Z",
     "start_time": "2024-06-13T20:35:08.575256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# how many distinct tasks have evaluation results\n",
    "# this will be distinct number of strings that start with \"evaluation_\" and end with \"_results.json\" but if they have \"-on-\" in the middle, it still counts as one\n",
    "\n",
    "# Find distinct tasks with evaluation results\n",
    "distinct_tasks_with_results = set()\n",
    "\n",
    "for file in json_files:\n",
    "    if file.startswith(\"evaluation_\") and file.endswith(\"_results.json\"):\n",
    "        if '-on-' in file:\n",
    "            task_name = file[len('evaluation_'):file.index('-on-')]\n",
    "            distinct_tasks_with_results.add(task_name)\n",
    "\n",
    "# Count the number of distinct tasks\n",
    "num_distinct_tasks = len(distinct_tasks_with_results)\n",
    "\n",
    "print(f\"Number of distinct tasks with evaluation results: {num_distinct_tasks}\")\n",
    "\n",
    "\n",
    "# find average number of evaluations per task\n",
    "total_evaluations = file_types['evaluation_results']\n",
    "\n",
    "average_evaluations_per_task = total_evaluations / num_distinct_tasks\n",
    "\n",
    "# format to 2 decimal places\n",
    "average_evaluations_per_task = \"{:.2f}\".format(average_evaluations_per_task)\n",
    "\n",
    "print(f\"Average number of evaluations per task: {average_evaluations_per_task}\")"
   ],
   "id": "f9b8ce64054f0b6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct tasks with evaluation results: 1681\n",
      "Average number of evaluations per task: 5.68\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Organized dataframes that will be inserted into the PostgreSQL database:",
   "id": "27eafa40b3f9bf63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dataframe 1: Tasks by Area\n",
    "\n",
    "For all 3371 tasks:\n",
    "\n",
    "Task1,Area,Parents,Children,NumEvaluations\n",
    "\n",
    "Task2,Area,Parents,Children,NumEvaluations\n",
    "\n",
    "Task3,Area,Parents,Children,NumEvaluations\n"
   ],
   "id": "9da5f7818d7cfe22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dataframe 2: Evaluations by Task\n",
    "\n",
    "For all 1681 tasks with evaluations:\n",
    "\n",
    "Task1,Eval1 (Dataset1),Metric1,Model1,Paper1,Date1\n",
    "\n",
    "Task1,Eval1 (Dataset1),Metric2,Model2,Paper2,Date2\n",
    "\n",
    "Task1,Eval1 (Dataset1),Metric3,Model3,Paper3,Date3\n",
    "\n",
    "Task1,Eval2 (Dataset2),Metric1,Model1,Paper1,Date1\n",
    "\n",
    "Task1,Eval2 (Dataset2),Metric2,Model2,Paper2,Date2\n",
    "\n",
    "Task2,Eval1 (Dataset1),Metric1,Model1,Paper1,Date1\n",
    "\n",
    "Task3,Eval1 (Dataset1),Metric1,Model1,Paper1,Date1\n",
    "\n",
    "Task3,Eval2 (Dataset2),Metric1,Model1,Paper1,Date1"
   ],
   "id": "5d19d7ed37cc285b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:36:14.956403Z",
     "start_time": "2024-06-23T00:36:14.897157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load tasks_layman_descriptions.csv and count number of rows\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tasks_layman_descriptions = pd.read_csv(\"../data/processed/tasks_layman_descriptions.csv\")\n",
    "\n",
    "num_tasks = tasks_layman_descriptions.shape[0]\n",
    "\n",
    "print(f\"Number of layman description tasks: {num_tasks}\")\n",
    "\n",
    "# load number of tassk in tasks_by_area.csv and count number of rows\n",
    "\n",
    "tasks_by_area = pd.read_csv(\"../data/processed/tasks_by_area.csv\")\n",
    "\n",
    "num_tasks_by_area = tasks_by_area.shape[0]\n",
    "\n",
    "print(f\"Number of tasks in tasks_by_area.csv: {num_tasks_by_area}\")\n",
    "\n",
    "# what percentage of tasks have layman descriptions\n",
    "\n",
    "percentage_tasks_with_layman_descriptions = (num_tasks / num_tasks_by_area) * 100\n",
    "\n",
    "# format to 2 decimal places\n",
    "\n",
    "percentage_tasks_with_layman_descriptions = \"{:.2f}\".format(percentage_tasks_with_layman_descriptions)\n",
    "\n",
    "print(f\"Percentage of tasks with layman descriptions: {percentage_tasks_with_layman_descriptions}%\")\n"
   ],
   "id": "20f99c52854f2560",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layman description tasks: 3371\n",
      "Number of tasks in tasks_by_area.csv: 3495\n",
      "Percentage of tasks with layman descriptions: 96.45%\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:35:26.180519Z",
     "start_time": "2024-06-23T00:35:26.138152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# find list of 'id' in tasks_by_area.csv that are not in 'task' col of tasks_layman_descriptions.csv'\n",
    "\n",
    "tasks_by_area_ids = tasks_by_area['id'].tolist()\n",
    "\n",
    "tasks_layman_descriptions_ids = tasks_layman_descriptions['task'].tolist()\n",
    "\n",
    "tasks_without_layman_descriptions = [task for task in tasks_by_area_ids if task not in tasks_layman_descriptions_ids]\n",
    "\n",
    "print(f\"Tasks without layman descriptions: {tasks_without_layman_descriptions}\")"
   ],
   "id": "bc8bc446fcf0b40f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks without layman descriptions: []\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T00:36:54.884149Z",
     "start_time": "2024-06-23T00:36:54.874207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# return list of duplicate 'id' in tasks_by_area.csv \n",
    "\n",
    "duplicate_tasks_by_area = tasks_by_area[tasks_by_area.duplicated(subset=['id'], keep=False)]\n",
    "\n",
    "print(f\"Duplicate tasks in tasks_by_area.csv: {duplicate_tasks_by_area}\")"
   ],
   "id": "acb4034b3e64000a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate tasks in tasks_by_area.csv:                              area                                          id  \\\n",
      "2                     methodology                  neural-network-compression   \n",
      "9                     methodology                                     chatbot   \n",
      "10                    methodology             multi-label-text-classification   \n",
      "11                    methodology                          continual-learning   \n",
      "13                    methodology                      cyber-attack-detection   \n",
      "...                           ...                                         ...   \n",
      "3360  natural-language-processing                             deep-clustering   \n",
      "3459  natural-language-processing              open-domain-question-answering   \n",
      "3466  natural-language-processing  semeval-2022-task-4-1-binary-pcl-detection   \n",
      "3481  natural-language-processing                                 code-repair   \n",
      "3491  natural-language-processing               multimodal-sentiment-analysis   \n",
      "\n",
      "                                              name  \\\n",
      "2                       Neural Network Compression   \n",
      "9                                          Chatbot   \n",
      "10                 Multi-Label Text Classification   \n",
      "11                              Continual Learning   \n",
      "13                          Cyber Attack Detection   \n",
      "...                                            ...   \n",
      "3360                               Deep Clustering   \n",
      "3459                Open-Domain Question Answering   \n",
      "3466  SemEval-2022 Task 4-1 (Binary PCL Detection)   \n",
      "3481                                   Code Repair   \n",
      "3491                 Multimodal Sentiment Analysis   \n",
      "\n",
      "                                            description  \\\n",
      "2                                                   NaN   \n",
      "9     **Chatbot** or conversational AI is a language...   \n",
      "10    According to Wikipedia \"In machine learning, m...   \n",
      "11    **Continual Learning** (also known as **Increm...   \n",
      "13    Cybersecurity attacks prediction using deep le...   \n",
      "...                                                 ...   \n",
      "3360                                                NaN   \n",
      "3459  Open-domain question answering is the task of ...   \n",
      "3466                                                NaN   \n",
      "3481                                                NaN   \n",
      "3491  Multimodal sentiment analysis is the task of p...   \n",
      "\n",
      "                                               children  \\\n",
      "2                                                   NaN   \n",
      "9                           chatbot,dialogue-generation   \n",
      "10                      multi-label-text-classification   \n",
      "11    continual-named-entity-recognition,class-incre...   \n",
      "13                               cyber-attack-detection   \n",
      "...                                                 ...   \n",
      "3360  deep-nonparametric-clustering,trajectory-clust...   \n",
      "3459                     open-domain-question-answering   \n",
      "3466         semeval-2022-task-4-1-binary-pcl-detection   \n",
      "3481                                        code-repair   \n",
      "3491                                                NaN   \n",
      "\n",
      "                                                parents  num_evals  \n",
      "2                   model-compression,2d-classification          1  \n",
      "9                                               chatbot          1  \n",
      "10    text-classification,multi-label-text-classific...         20  \n",
      "11                                   continual-learning         29  \n",
      "13           cyber-attack-detection,activity-prediction          0  \n",
      "...                                                 ...        ...  \n",
      "3360                                    deep-clustering          5  \n",
      "3459  question-answering,open-domain-question-answering         15  \n",
      "3466  pcl-detection,semeval-2022-task-4-1-binary-pcl...          1  \n",
      "3481                                        code-repair          1  \n",
      "3491                                 sentiment-analysis          5  \n",
      "\n",
      "[242 rows x 7 columns]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Well that makes sense. 242 duplicates mean 121 tasks are repeated in the tasks_by_area.csv file.\n",
    "\n",
    "3371 + 121 = 3492, which is the total number of tasks in the dataset."
   ],
   "id": "6f185c02696ba5a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "851f82b496f41fd7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
